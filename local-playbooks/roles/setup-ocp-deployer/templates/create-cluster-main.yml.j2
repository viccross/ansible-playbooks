#jinja2:block_start_string:'[%', block_end_string:'%]', variable_start_string:'[[', variable_end_string:']]'
---
# tasks file for create-cluster

- name: Grab the pull secret
  stat:
    path: '{{ webroot }}/.secret/{{ cluster["secret"] }}'
  register: ps
- name: abort if the pull secret is not present
  fail:
    msg: "OCP pull secret is not found!"
  when: ps.stat.size == 0

- name: remove prior openshift workdir
  file:
    path: "{{ workdir }}"
    state: absent

- name: create openshift workdir
  file:
    path: "{{ workdir }}"
    state: "directory"
    owner: "csid_{{ cluster_name }}"
    group: rhocp_clusters
    mode: 06755

- name: Set up SSH for Ansible - slurp pubkey
  slurp:
    src: ~csid_{{ cluster_name }}/.ssh/id_ed25519.pub
  register: bastion_pubkey

# install config is deleted when ignition
# configs are created.  this task also
# creates a copy to check for debugging
- name: generate install-config.yaml
  tags: config
  template:
    dest: "{{ workdir }}/{{ item }}"
    src: install-config.yaml.j2
    mode: 0644
  with_items:
  - install-config.yaml
  - install-config.copy.yaml

- name: create ignition configs
  tags: config
  shell: "/opt/rhocp/install/{{ cluster['OCPVer'] }}/install/openshift-install --dir=`pwd` create ignition-configs"
  args:
    chdir: "{{ workdir }}"
    creates: "{{ workdir }}/metadata.json"

- name: create additional config mods in ignition
  block:
  - name: back up the ignition files
    tags: config
    shell: ls {{ workdir }}/*.ign
    register: ign_raw
  - name: back up ignition configs
    tags: config
    copy:
      src: "{{ item }}"
      dest: "{{ item }}.bak"
      remote_src: yes
      mode: 0644
    with_items: "{{ ign_raw.stdout_lines }}"
  - name: create bootstrap directory
    file:
      path: "{{ workdir }}/bootstrap/etc"
      state: directory
      mode: 0755
  - name: create our chrony.conf file
    template:
      dest: "{{ workdir }}/bootstrap/etc/chrony.conf"
      src: chrony.conf.j2
      mode: 0644
  - name: filetranspile the ignition files
    command: filetranspile -i {{ item }}.bak -f bootstrap -o {{ item }}{{ '' }}
    args:
      chdir: "{{ workdir }}"
    with_items: "{{ ign_raw.stdout_lines }}"
#  - name: create ignition manifests
#    tags: config
#    shell: "openshift-install --dir=`pwd` create manifests"
#    args:
#      chdir: "{{ workdir }}"
#      creates: "{{ workdir }}/manifests"
#  - name: create manifest files for chrony config
#    template:
#      dest: "{{ workdir }}/manifests/99_{% raw %}{{ item }}{% endraw %}-chrony-configuration.yaml"
#      src: chrony-manifest.yaml.j2
#      mode: 0644
#    loop:
#      - "master"
#      - "worker"
#  - name: copy/recover the install-config.yaml
#    copy:
#      src: "{{ workdir }}/install-config.copy.yaml"
#      dest: "{{ workdir }}/install-config.yaml"
#      mode: 0644
#  - name: re-create ignition configs
#    tags: config
#    shell: "openshift-install --dir=`pwd` create ignition-configs"
#    args:
#      chdir: "{{ workdir }}"

- block:
  - name: make ignition config directory
    file:
      path: "/var/www/html/ignition/{{ cluster_name }}"
      state: directory
      mode: 0755
  - name: get ign files
    tags: config
    shell: ls {{ workdir }}/*.ign
    register: ign_raw
  - name: copy ignition configs to cluster ignition directory
    tags: config
    copy:
      src: "{{ item }}"
      dest: "/var/www/html/ignition/{{ cluster_name }}/"
      remote_src: yes
      mode: 0644
    with_items: "{{ ign_raw.stdout_lines }}"

- name: install kubeconfig
  tags: wait-install
  copy:
    src: "{{ workdir }}/auth/kubeconfig"
    dest: "~csid_{{ cluster_name }}/.kube/config"
    remote_src: yes
    force: yes
    mode: 0640

- name: create /etc/hosts entry
  tags: etc-hosts
  connection: local
  copy:
    dest: "{{ playbook_dir }}/../etc.hosts"
    mode: 0644
    content: >
      {{ bastion_public_ip_address }}
      bastion.{{ cluster_domain_name }}
      api.{{ cluster_domain_name }}
      console-openshift-console.apps.{{ cluster_domain_name }}
      oauth-openshift.apps.{{ cluster_domain_name }}

- name: boot the bootstrap node
  include_tasks: boot-guest.yml
  vars:
    coreos_role: bootstrap
  with_items: "{{ cluster['nodes'][coreos_role] }}"

- name: boot the control nodes
  include_tasks: boot-guest.yml
  vars:
    coreos_role: control
  with_items: "{{ cluster['nodes'][coreos_role] }}"

- name: boot the compute nodes
  include_tasks: boot-guest.yml
  vars:
    coreos_role: compute
  with_items: "{{ cluster['nodes'][coreos_role] }}"
  when: cluster['nodes'].compute is defined

- name: wait for bootstrap node accessibility
  wait_for:
    port: 22
    host: "{{ cluster['nodes']['bootstrap'][item].ip }}"
    search_regex: OpenSSH
    delay: 1
    timeout: 10000
  with_items: "{{ cluster['nodes']['bootstrap'] }}"

- name: wait for master node accessibility
  wait_for:
    port: 22
    host: "{{ cluster['nodes']['control'][item].ip }}"
    search_regex: OpenSSH
    delay: 1
    timeout: 5000
  with_items: "{{ cluster['nodes']['control'] }}"

- name: wait for bootstrap complete # noqa 301
  tags: config
  shell: /opt/rhocp/install/{{ cluster['OCPVer'] }}/install/openshift-install --dir=`pwd` wait-for bootstrap-complete --log-level debug
  args:
    chdir: "{{ workdir }}"
  register: result
  retries: 2
  delay: 0
  until: result is not failed

- name: shut down the bootstrap node # noqa 301
  shell: smcli id -T {{ cluster['nodes']['bootstrap'][item].name }} -t 'WITHIN 60' -H [[ ocp_smapi_host|quote ]] -U [[ ocp_smapi_user|quote ]] -P [[ ocp_smapi_password|quote ]]
  with_items: "{{ cluster['nodes']['bootstrap'] }}"

- name: give the bootstrap time to shut down
  pause:
    minutes: 1
  when: cluster['nodes'].bootcompute is defined

- name: rename the bootstrap node for conversion # noqa 301
  shell: smcli ichid -T {{ cluster['nodes']["bootstrap"]['bootstrap']['name'] }} -n {{ cluster['nodes']["bootcompute"]['compute-2']['name'] }} -H [[ ocp_smapi_host|quote ]] -U [[ ocp_smapi_user|quote ]] -P [[ ocp_smapi_password|quote ]]
  when: cluster['nodes'].bootcompute is defined

- name: make sure converted node can access the config disk
  shell:
    cmd: |
      ldapmodify -Zx -h LDAPSRV.ibmpoc.internal -p 389 -D racfid=IBMAUTO,profiletype=user,o=ibmzvm -w 'jTghTGinJupD63yh' <<EOFLDIF
      dn: profilename=[[ znetboot_cfg_disk | replace(' ','.') ]],profiletype=VMMDISK,o=ibmzvm
      changetype: modify
      add: racfaccesscontrol
      racfaccesscontrol: ID({{ cluster['nodes']['bootcompute'][item].name }}) ACCESS(READ) COUNT(0)
      EOFLDIF
  with_items: "{{ cluster['nodes']['bootcompute'] }}"
  when: cluster['nodes'].bootcompute is defined

- name: boot the converted compute node
  include_tasks: boot-guest.yml
  vars:
    coreos_role: bootcompute
  with_items: "{{ cluster['nodes'][coreos_role] }}"
  when: cluster['nodes'].bootcompute is defined

- name: wait for compute node accessibility
  wait_for:
    port: 22
    host: "{{ cluster['nodes']['compute'][item].ip }}"
    search_regex: OpenSSH
    delay: 1
    timeout: 5000
  with_items: "{{ cluster['nodes']['compute'] }}"
  when: cluster['nodes'].compute is defined

- name: start the approve-csrs task
  systemd:
    name: ocp-approve-csrs
    state: started

- name: wait for install complete # noqa 301
  tags: wait-install
  shell: /opt/rhocp/install/{{ cluster['OCPVer'] }}/install/openshift-install --dir=`pwd` wait-for install-complete
  args:
    chdir: "{{ workdir }}"
  register: result
  retries: 2
  delay: 0
  until: result is not failed

- name: update boot device on the master nodes
  include_tasks: guest-IPLdev.yml
  vars:
    coreos_role: control
  with_items: "{{ cluster['nodes'][coreos_role] }}"

- name: update boot device on the worker nodes
  include_tasks: guest-IPLdev.yml
  vars:
    coreos_role: compute
  with_items: "{{ cluster['nodes'][coreos_role] }}"
  when: cluster['nodes'].compute is defined

- name: update boot device on the converted bootstrap node
  include_tasks: guest-IPLdev.yml
  vars:
    coreos_role: bootcompute
  with_items: "{{ cluster['nodes'][coreos_role] }}"
  when: cluster['nodes'].bootcompute is defined

- name: configure the cluster (LDAP, ingress certificate)
  include_tasks: configure-cluster.yml

- name: enable the start-the-guests service
  systemd:
    name: ocp-guests-start
    state: stopped
    enabled: yes

- name: give the converted bootstrap node time to build
  pause:
    minutes: 10

- name: stop the approve-csrs task
  systemd:
    name: ocp-approve-csrs
    state: stopped
